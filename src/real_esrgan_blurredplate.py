# -*- coding: utf-8 -*-
"""Real-ESRGAN_Shojai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10T8stTxN5ybcn6M973sKBRTy7rz-XzjN

# 1. Preparations
Before start, make sure that you choose
* Runtime Type = Python 3
* Hardware Accelerator = GPU

in the **Runtime** menu -> **Change runtime type**

Then, we clone the repository, set up the envrironment.
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone Real-ESRGAN and enter the Real-ESRGAN
!git clone https://github.com/xinntao/Real-ESRGAN.git
# %cd Real-ESRGAN
# Set up the environment
!pip install basicsr
!pip install facexlib
!pip install gfpgan
!pip install -r requirements.txt
!python setup.py develop

"""# 2. Upload Images

Upload the images to be processed by Real-ESRGAN.

I used the dataset https://github.com/mut-deep/IR-LPR for its license plate number section.
"""

# Ù†ØµØ¨ gdown Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ
!pip install gdown -q

# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
!mkdir -p /content/IR_LPR_data/all_images
!mkdir -p /content/Real-ESRGAN/upload
!mkdir -p /content/Real-ESRGAN/results

# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ø± Ø³Ù‡ ÙØ§ÛŒÙ„ zip
!gdown --id 1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM -O /content/IR_LPR_data/file1.zip
!gdown --id 1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I -O /content/IR_LPR_data/file2.zip
!gdown --id 1lLh_kxrHy1teUB2NguHVuOZwA5rjL5kx -O /content/IR_LPR_data/file3.zip

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ø± Ø³Ù‡ ÙØ§ÛŒÙ„ Ø¯Ø± Ù¾ÙˆØ´Ù‡â€ŒÛŒ all_images
!unzip -q /content/IR_LPR_data/file1.zip -d /content/IR_LPR_data/all_images/
!unzip -q /content/IR_LPR_data/file2.zip -d /content/IR_LPR_data/all_images/
!unzip -q /content/IR_LPR_data/file3.zip -d /content/IR_LPR_data/all_images/

import os
import shutil
import random
from glob import glob

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
src_root = '/content/IR_LPR_data/all_images'   # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ unzip Ø´Ø¯Ù‡
intermediate_root = '/content/Real-ESRGAN/all_flat'  # Ù¾ÙˆØ´Ù‡ Ø«Ø§Ù†ÙˆÛŒÙ‡
upload_root = '/content/Real-ESRGAN/upload'   # Ù¾ÙˆØ´Ù‡ Ù†Ù‡Ø§ÛŒÛŒ upload

# Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
os.makedirs(intermediate_root, exist_ok=True)
os.makedirs(upload_root, exist_ok=True)

# Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ jpg Ø§Ø² Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
image_paths = glob(os.path.join(src_root, '*', '*.jpg'))

# Ø§Ù†ØªÙ‚Ø§Ù„ ØªØµØ§ÙˆÛŒØ± Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ Ø«Ø§Ù†ÙˆÛŒÙ‡
for path in image_paths:
    filename = os.path.basename(path)
    dst_path = os.path.join(intermediate_root, filename)

    base, ext = os.path.splitext(filename)
    counter = 1
    while os.path.exists(dst_path):
        dst_path = os.path.join(intermediate_root, f"{base}_{counter}{ext}")
        counter += 1

    shutil.copy(path, dst_path)

print(f"{len(image_paths)} ÙØ§ÛŒÙ„ JPG Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯ Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ Ø«Ø§Ù†ÙˆÛŒÙ‡: {intermediate_root}")

# Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ Û³Û°Ùª ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ upload
all_intermediate = glob(os.path.join(intermediate_root, '*.jpg'))
selected_count = int(0.3 * len(all_intermediate))
selected_images = random.sample(all_intermediate, selected_count)

# Ø§Ù†ØªÙ‚Ø§Ù„ ØªØµØ§ÙˆÛŒØ± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ upload
for path in selected_images:
    filename = os.path.basename(path)
    dst_path = os.path.join(upload_root, filename)
    shutil.copy(path, dst_path)

print(f"{len(selected_images)} ÙØ§ÛŒÙ„ JPG Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ù†Ø¯ÙˆÙ… Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ upload Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯.")

"""# 3. Inference"""

# if it is out of memory, try to use the `--tile` option
# We upsample the image with the scale factor X3.5
!python inference_realesrgan.py -n RealESRGAN_x4plus -i upload
# Arguments
# -n, --model_name: Model names
# -i, --input: input folder or image
# --outscale: Output scale, can be arbitrary scale factore.

"""# 4. Visualization"""

import os
import glob
import random
import cv2
import matplotlib.pyplot as plt

input_folder = 'upload'
result_folder = 'results'

# ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØªØµØ§Ø¯ÙÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒÙ… Ø¨Ø¨ÛŒÙ†ÛŒÙ…
num_samples = 10

# Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ
input_list = glob.glob(os.path.join(input_folder, '*.jpg'))
input_sample = random.sample(input_list, min(num_samples, len(input_list)))

# Ù„ÛŒØ³Øª Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…Ø³ÛŒØ± Ø¬ÙØªâ€ŒÙ‡Ø§
paired_paths = []

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±
def imread(img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

# ØªØ§Ø¨Ø¹ Ù†Ù…Ø§ÛŒØ´
def display(img1, img2, name):
    fig = plt.figure(figsize=(15, 6))
    ax1 = fig.add_subplot(1, 2, 1)
    ax1.imshow(img1)
    ax1.set_title('Input image: ' + name, fontsize=14)
    ax1.axis('off')

    ax2 = fig.add_subplot(1, 2, 2)
    ax2.imshow(img2)
    ax2.set_title('Real-ESRGAN Output:', fontsize=14)
    ax2.axis('off')
    plt.show()

# Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÙˆØ±ÙˆØ¯ÛŒØŒ Ø®Ø±ÙˆØ¬ÛŒ Ù…ØªÙ†Ø§Ø¸Ø± Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ù† Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
for input_path in input_sample:
    base_name = os.path.splitext(os.path.basename(input_path))[0]

    # Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ Ù‡Ù…Ø§Ù† Ù†Ø§Ù… Ù¾Ø§ÛŒÙ‡
    candidates = glob.glob(os.path.join(result_folder, base_name + '*'))
    if not candidates:
        print(f'â›” ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ {base_name} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!')
        continue

    output_path = candidates[0]  # Ø§ÙˆÙ„ÛŒÙ† ÙØ§ÛŒÙ„ Ù…Ø·Ø§Ø¨Ù‚ Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…

    paired_paths.append((input_path, output_path))  # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø³ÛŒØ± Ø¬ÙØª

    img_input = imread(input_path)
    img_output = imread(output_path)
    display(img_input, img_output, base_name)

"""# 5. Measurement criteria

**1.   NIQE(Naturalness Image Quality Evaluator)**
"""

from basicsr.metrics.niqe import calculate_niqe
from PIL import Image
import numpy as np
import os
import glob

def get_niqe_basicsr(img_path):
    img = Image.open(img_path).convert('RGB')
    img = img.resize((512, 512))
    img_np = np.array(img)
    return calculate_niqe(img_np, crop_border=0)

niqe_inputs = []
niqe_outputs = []

print("ğŸ” NIQE Ø¨Ø±Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ (paired_paths):\n" + "="*50)

for input_path, output_path in paired_paths:
    try:
        niqe_in = get_niqe_basicsr(input_path)
        niqe_out = get_niqe_basicsr(output_path)
        niqe_inputs.append(niqe_in)
        niqe_outputs.append(niqe_out)

        status = "âœ… Ø¨Ù‡Ø¨ÙˆØ¯" if niqe_out < niqe_in else "ğŸ”» Ù¾Ø³Ø±ÙØª"
        print(f"ğŸ“¸ {os.path.basename(input_path)}")
        print(f"    Input NIQE : {niqe_in:.2f}")
        print(f"    Output NIQE: {niqe_out:.2f}")
        print(f"    ğŸ” Ù†ØªÛŒØ¬Ù‡: {status}")
        print('-' * 40)

    except Exception as e:
        print(f"â›” Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {input_path}: {e}")

# Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† NIQE Ø¨Ø±Ø§ÛŒ paired_paths
mean_niqe_in = sum(niqe_inputs) / len(niqe_inputs)
mean_niqe_out = sum(niqe_outputs) / len(niqe_outputs)
overall_result = "âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ù„ÛŒ" if mean_niqe_out < mean_niqe_in else "ğŸ”» Ø§ÙØª Ú©Ù„ÛŒ"

print("\nğŸ“Š Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† NIQE Ø¨Ø±Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡:")
print(f"    Input Mean NIQE : {mean_niqe_in:.2f}")
print(f"    Output Mean NIQE: {mean_niqe_out:.2f}")
print(f"    ğŸ” Ù†ØªÛŒØ¬Ù‡ Ú©Ù„ÛŒ: {overall_result}")
print("=" * 50)

"""**2. OCR Model**

I used https://huggingface.co/hezarai/crnn-fa-license-plate-recognition-v2 to read persian license plates.
"""

!pip install hezar

import os
import glob
import random
import cv2
import matplotlib.pyplot as plt
from hezar.models import Model

#lp_ocr = Model.load("hezarai/crnn-fa-64x256-license-plate-recognition")
lp_ocr = Model.load("hezarai/crnn-fa-license-plate-recognition-v2")


# ØªØ§Ø¨Ø¹ Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±
def imread(img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

# Ù†Ù…Ø§ÛŒØ´ ØªØµØ§ÙˆÛŒØ± Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„
for input_path, output_path in paired_paths:
    # Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµØ§ÙˆÛŒØ±
    img_input = imread(input_path)
    img_output = imread(output_path)

    # ØªØ´Ø®ÛŒØµ Ù¾Ù„Ø§Ú©
    plate_input = lp_ocr.predict(img_input)
    plate_output = lp_ocr.predict(img_output)

    # Ù†Ù…Ø§ÛŒØ´ ØªØµØ§ÙˆÛŒØ±
    fig = plt.figure(figsize=(15,6))
    ax1 = fig.add_subplot(1,2,1)
    ax1.imshow(img_input)
    ax1.set_title(f"Input Image\nPlate: {plate_input}", fontsize=14)
    ax1.axis('off')

    ax2 = fig.add_subplot(1,2,2)
    ax2.imshow(img_output)
    ax2.set_title(f"ESRGAN Output\nPlate: {plate_output}", fontsize=14)
    ax2.axis('off')

    plt.show()

"""# 6. Dowmload input and output"""

from google.colab import files
# Download the upload
zip_filename = 'Real-ESRGAN_upload.zip'
if os.path.exists(zip_filename):
  os.remove(zip_filename)
os.system(f"zip -r -j {zip_filename} upload/*")
files.download(zip_filename)

# Download the results
zip_filename = 'Real-ESRGAN_result.zip'
if os.path.exists(zip_filename):
  os.remove(zip_filename)
os.system(f"zip -r -j {zip_filename} results/*")
files.download(zip_filename)